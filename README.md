# New Approach for Splicing Analysis (NASA)

## Rôle du pipeline

Le but du pipeline est de détecter de nouveaux évènements d’épissages chez le virus de la grippe à partir d'un fichier d'aligment au format .bam (sortie de [STAR](https://github.com/alexdobin/STAR)) 

**Fichier d'entrée** : Les fichiers d'entrées sont les fichiers d'alignement des reads RNAseq viraux contre le génome du virus (souche A/WSN/33) : un fichier par condition et par réplicat

**Fichier de sortie** : Les fichiers de sortie contiennent la liste des jonctions retrouvées dans les différents fichiers .bam (un fichier résultat par fichier .bam).

L'en-tête des fichiers est le suivant : 

    Segment	Gene	Junction_First_Position	Junction_Second_Position	Strand	Len_not_Spliced	Len_Spliced	GC_not_Spliced	GC_Spliced	Seq3(maxentscan)	Seq5(maxentscan)	MaxEntScan3	MaxEntScan5	not_Spliced	Spliced
   
Exemple de résultat obtenue :

    CY010795.1	PB2	167	2195	+	2280	251	44.07894736842105	44.6215139442231	GAAGGCTAATGTGCTAATTGGGC	TGATGGCAA	-31.9136840922	-6.74180412924	ATGGAAAGAATAAAAGAACTAAGGAATCTAATGTCGCAGTCTCGCACTCGCGAGATACTCACAAAAACCACCGTGGACCATATGGCCATAATCAAGAAGTACACATCAGGAAGACAGGAGAAGAACCCAGCACTTAGGATGAAATGGATGATGGCAATGAAATATCCAATTACAGCAGACAAGAGGATAACGGAAATGATTCCTGAGAGAAATGAGCAGGGACAAACTTTATGGAGTAAAATGAATGACGCCGGATCAGACCGAGTGATGGTATCACCTCTGGCTGTGACATGGTGGAATAGGAATGGACCAGTGACAAGTACAGTTCATTATCCAAAAATCTACAAAACTTATTTTGAAAAAGTCGAAAGGTTAAAACATGGAACCTTTGGCCCTGTCCATTTTAGAAACCAAGTCAAAATACGTCGAAGAGTTGACATAAATCCTGGTCATGCAGATCTCAGTGCCAAAGAGGCACAGGATGTAATCATGGAAGTTGTTTTCCCTAACGAAGTGGGAGCCAGGATACTAACATCGGAATCGCAACTAACGACAACCAAAGAGAAGAAAGAAGAACTCCAGGGTTGCAAAATTTCTCCTCTGATGGTGGCATACATGTTGGAGAGAGAACTGGTCCGCAAAACGAGATTCCTCCCAGTGGCTGGTGGAACAAGCAGTGTGTACATTGAAGTGTTGCATTTGACCCAAGGAACATGCTGGGAACAGATGTACACTCCAGGAGGGGAGGCGAGGAATGATGATGTTGATCAAAGCTTAATTATTGCTGCTAGAAACATAGTAAGAAGAGCCACAGTATCAGCAGATCCACTAGCATCTTTATTGGAGATGTGCCACAGCACGCAGATTGGTGGAATAAGGATGGTAAACATCCTTAGGCAGAACCCAACAGAAGAGCAAGCCGTGGATATTTGCAAGGCTGCAATGGGACTGAGAATTAGCTCATCCTTCAGTTTTGGTGGATTCACATTTAAGAGAACAAGCGGATCATCAGTCAAGAGAGAGGAAGAGGTGCTTACGGGCAATCTTCAGACATTGAAGATAAGAGTGCATGAGGGATATGAAGAGTTCACAATGGTTGGGAGAAGAGCAACAGCTATACTCAGAAAAGCAACCAGGAGATTGATTCAGCTGATAGTGAGTGGGAGAGACGAACAGTCGATTGCCGAAGCAATAATTGTGGCCATGGTATTTTCACAAGAGGATTGTATGATAAAAGCAGTTAGAGGTGACCTGAATTTCGTCAATAGGGCGAATCAGCGATTGAATCCCATGCACCAACTTTTGAGACATTTTCAGAAGGATGCAAAGGTGCTCTTTCAAAATTGGGGAATTGAATCCATCGACAATGTGATGGGAATGATCGGGATATTGCCCGACATGACTCCAAGCACCGAGATGTCAATGAGAGGAGTGAGAATCAGCAAAATGGGGGTAGATGAGTATTCCAGCGCGGAGAAGATAGTGGTGAGCATTGACCGTTTTTTGAGAGTTAGGGACCAACGTGGGAATGTACTACTGTCTCCCGAGGAGGTCAGTGAAACACAGGGAACAGAGAAACTGACAATAACTTACTCATCGTCAATGATGTGGGAGATTAATGGTCCTGAATCAGTGTTGGTCAATACCTATCAGTGGATCATCAGAAACTGGGAAACTGTTAAAATTCAGTGGTCCCAGAATCCTACAATGCTGTACAATAAAATGGAATTTGAGCCATTTCAGTCTTTAGTTCCAAAGGCCGTTAGAGGCCAATACAGTGGGTTTGTGAGAACTCTGTTCCAACAAATGAGGGATGTGCTTGGGACATTTGATACCGCTCAGATAATAAAACTTCTTCCCTTCGCAGCCGCTCCACCAAAGCAAAGTGGAATGCAGTTCTCCTCATTGACTATAAATGTGAGGGGATCAGGAATGAGAATACTTGTAAGGGGCAATTCTCCAGTATTCAACTACAACAAGACCACTAAAAGACTCACAGTTCTCGGAAAGGATGCTGGCCCTTTAACTGAAGACCCAGATGAAGGCACAGCTGGAGTTGAGTCCGCAGTTCTGAGAGGATTCCTCATTCTGGGCAAAGAAGACAGGAGATATGGACCAGCATTAAGCATAAATGAACTGAGCAACCTTGCGAAAGGAGAGAAGGCTAATGTGCTAATTGGGCAAGGAGACGTGGTGTTGGTAATGAAACGGAAACGGAACTCTAGCATACTTACTGACAGCCAGACAGCGACCAAAAGAATTCGGATGGCCATCAATTAG	ATGGAAAGAATAAAAGAACTAAGGAATCTAATGTCGCAGTCTCGCACTCGCGAGATACTCACAAAAACCACCGTGGACCATATGGCCATAATCAAGAAGTACACATCAGGAAGACAGGAGAAGAACCCAGCACTTAGGATGAAATGGATGAGCAAGGAGACGTGGTGTTGGTAATGAAACGGAAACGGAACTCTAGCATACTTACTGACAGCCAGACAGCGACCAAAAGAATTCGGATGGCCATCAATTAG

    
## Logiciel requis

biopython  
sjcount  


## Pipeline

Le pipeline s'exécute via le script Pipeline_Final.sh (Attention ! Il faut être à la racine pour exécuter le script):

    ./SCRIPTS/Pipeline_Final.sh #Rajouter les arguments : dossier_bam genome gff sortie

Arguments :

#TODO avec les valeurs par défauts

Les différentes étapes de l'analyse sont :
1. Utilisation de Sjcount sur chaque fichier .bam présents dans le dossier fournis en argument : `#Rajouter le nom du script`  
Sjcount va sortir les jonctions d'épissages (Junction) et les jonctions correspondant au transcript non épissé (Count). 
2. Les jonctions sont ensuite récupérés par rapport au seuil donné en argument du pipeline (seuil = pourcentage de read confirmant l'épissage) : `.py` et `.sh`
Les fichiers créés contiennent les jonctions au format csv.
3. MaxEntScan est ensuite exécuté sur les jonctions obtenues précédemment pour déterminer la force des sites d'épissages : `.py` et `.sh` 
4. Enfin le dernier scripts permet d'assembler les résultats précedemment obtenues et calcul quelques statistique basic tel que les taux de gc des séquences épissé et non épissé : `.py` et `.sh`

L'arborescence de la sortie est la suivante :

    $ NASA
    .
    ├── Logs
    │   ├── sjcount.log
    ├── Sjcount
    │   ├── Junction
    │   │   └── Fichiers_Junction.txt 
    │   └── Count
    │       └── Fichiers_Count.txt
    ├── Junctions
    │   └── Fichiers_Junction_Filter.csv
    ├── MaxEntScan
    │   └── Fichiers_MaxEntScan.csv    
    └── Analyse
        └── Fichiers_All.csv



 
